{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook carries out the training of wGAN gp model on two datasets (high and low confluence level) of U2-OS cell painting image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pathlib\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pathlib.Path('.').absolute().parent.parent / \"config.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import virtual_stain_flow software "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/weishanli/Waylab/pediatric_cancer_atlas_analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weishanli/anaconda3/envs/speckle_analysis/lib/python3.11/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.5' (you have '2.0.4'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(config['paths']['software_path'])\n",
    "print(str(pathlib.Path('.').absolute().parent.parent))\n",
    "\n",
    "## Dataset\n",
    "from virtual_stain_flow.datasets.PatchDataset import PatchDataset\n",
    "from virtual_stain_flow.datasets.CachedDataset import CachedDataset\n",
    "\n",
    "## wGaN training\n",
    "from virtual_stain_flow.models.unet import UNet\n",
    "from virtual_stain_flow.models.discriminator import GlobalDiscriminator\n",
    "from virtual_stain_flow.trainers.WGANTrainer import WGANTrainer\n",
    "\n",
    "## wGaN losses\n",
    "from virtual_stain_flow.losses.GradientPenaltyLoss import GradientPenaltyLoss\n",
    "from virtual_stain_flow.losses.DiscriminatorLoss import WassersteinLoss\n",
    "from virtual_stain_flow.losses.GeneratorLoss import GeneratorLoss\n",
    "\n",
    "from virtual_stain_flow.transforms.MinMaxNormalize import MinMaxNormalize\n",
    "from virtual_stain_flow.transforms.PixelDepthTransform import PixelDepthTransform\n",
    "\n",
    "## Metrics\n",
    "from virtual_stain_flow.metrics.MetricsWrapper import MetricsWrapper\n",
    "from virtual_stain_flow.metrics.PSNR import PSNR\n",
    "from virtual_stain_flow.metrics.SSIM import SSIM\n",
    "\n",
    "## callback\n",
    "from virtual_stain_flow.callbacks.MlflowLogger import MlflowLogger\n",
    "from virtual_stain_flow.callbacks.IntermediatePlot import IntermediatePlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths and other train parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loaddata for train\n",
    "LOADDATA_FILE_PATH = pathlib.Path('.').absolute().parent.parent \\\n",
    "    / '0.data_preprocessing' / 'data_split_loaddata' / 'loaddata_train.csv'\n",
    "assert LOADDATA_FILE_PATH.exists()\n",
    "\n",
    "LOADDATA_HELDOUT_FILE_PATH = pathlib.Path('.').absolute().parent.parent \\\n",
    "    / '0.data_preprocessing' / 'data_split_loaddata' / 'loaddata_heldout.csv'\n",
    "assert LOADDATA_HELDOUT_FILE_PATH.exists(), f\"Directory not found: {LOADDATA_HELDOUT_FILE_PATH}\"\n",
    "\n",
    "SC_FEATURES_DIR = pathlib.Path(config['paths']['sc_features_path'])\n",
    "\n",
    "## Train Logging/Weight output directory\n",
    "MLFLOW_DIR = pathlib.Path('.').absolute() / 'mlflow'\n",
    "MLFLOW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "## Train intermediate plot otuput directory\n",
    "PLOT_DIR = pathlib.Path('.').absolute() / 'train_plots'\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "## Basic data generation, model convolutional depth and max epoch definition\n",
    "PATCH_SIZE = 256\n",
    "EPOCHS = 1_000\n",
    "\n",
    "## Channels for input and target are read from config\n",
    "INPUT_CHANNEL_NAMES = config['data']['input_channel_keys']\n",
    "TARGET_CHANNEL_NAMES = config['data']['target_channel_keys']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defines how the train data will be divided to train models on two levels of confluence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_GROUPING = {\n",
    "    'high_confluence': {\n",
    "        'seeding_density': [12_000, 8_000]\n",
    "    },\n",
    "    'low_confluence': {\n",
    "        'seeding_density': [4_000, 2_000, 1_000]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fns = {\n",
    "    \"mse_loss\": MetricsWrapper(_metric_name='mse', module=torch.nn.MSELoss()),\n",
    "    \"ssim_loss\": SSIM(_metric_name=\"ssim\"),\n",
    "    \"psnr_loss\": PSNR(_metric_name=\"psnr\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparams as described by Cross-Zamirski\n",
    "https://www.nature.com/articles/s41598-022-12914-x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN_DEPTHS = [4, 5]\n",
    "\n",
    "GEN_DEPTH = 4\n",
    "GEN_OPTIM_LR = 2e-4\n",
    "GEN_OPTIM_BETA0 = 0.0\n",
    "GEN_OPTIM_BETA1 = 0.9\n",
    "GEN_OPTIM_WEIGHT_DECAY = 0\n",
    "GEN_UPDATE_FREQ = 5\n",
    "\n",
    "DISC_DEPTH = 4\n",
    "DISC_N_FILTERS = 64\n",
    "DISC_OPTIM_LR = 2e-4\n",
    "DISC_OPTIM_BETA0 = 0.0\n",
    "DISC_OPTIM_BETA1 = 0.9\n",
    "DISC_OPTIM_WEIGHT_DECAY = 1e-3\n",
    "DISC_UPDATE_FREQ = 1 # discriminator updated every epoch\n",
    "\n",
    "GP_WEIGHT = 10.0\n",
    "\n",
    "BATCH_SIZE = 16 # reduce vRAM usage\n",
    "PATIENCE = 20 # fixed patience for early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create patched dataset from heldout data for use with plotting predictions during training\n",
    "Heldout is not used as training data, just visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaddata_heldout_df = pd.read_csv(LOADDATA_HELDOUT_FILE_PATH)\n",
    "## Retrieve relevant sc feature information\n",
    "sc_features = pd.DataFrame()\n",
    "for plate in loaddata_heldout_df['Metadata_Plate'].unique():\n",
    "    sc_features_parquet = SC_FEATURES_DIR / f'{plate}_sc_normalized.parquet'\n",
    "    if not sc_features_parquet.exists():\n",
    "        print(f'{sc_features_parquet} does not exist, skipping...')\n",
    "        continue \n",
    "    else:\n",
    "        sc_features = pd.concat([\n",
    "            sc_features, \n",
    "            pd.read_parquet(\n",
    "                sc_features_parquet,\n",
    "                columns=['Metadata_Plate', 'Metadata_Well', 'Metadata_Site', 'Metadata_Cells_Location_Center_X', 'Metadata_Cells_Location_Center_Y']\n",
    "            )\n",
    "        ])\n",
    "\n",
    "## Generate multi-channel patch dataset for plotting\n",
    "pds_heldout = PatchDataset(\n",
    "        _loaddata_csv=loaddata_heldout_df,\n",
    "        _sc_feature=sc_features,\n",
    "        _input_channel_keys=INPUT_CHANNEL_NAMES,\n",
    "        _target_channel_keys=TARGET_CHANNEL_NAMES,\n",
    "        _input_transform=PixelDepthTransform(src_bit_depth=16, target_bit_depth=8, _always_apply=True),\n",
    "        _target_transform=MinMaxNormalize(_normalization_factor=(2 ** 16) - 1, _always_apply=True),\n",
    "        patch_size=PATCH_SIZE,\n",
    "        verbose=False,\n",
    "        patch_generation_method=\"random_cell\",\n",
    "        n_expected_patches_per_img=5,\n",
    "        patch_generation_random_seed=42\n",
    "    )\n",
    "\n",
    "## Generate list of indice to plot\n",
    "n_patches = len(pds_heldout)\n",
    "random.seed(42)\n",
    "visualization_patch_indices = random.sample(range(n_patches), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models per confluence level per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training wGAN-gp for channel: OrigDNA for high_confluence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/26 14:13:39 INFO mlflow.tracking.fluent: Experiment with name 'wGAN_gp_prototype_train_high_confluence' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early termination at epoch 27 with best validation metric -0.210029647900508\n",
      "Beginning training wGAN-gp for channel: OrigER for high_confluence\n",
      "Early termination at epoch 30 with best validation metric -0.023256127650921162\n",
      "Beginning training wGAN-gp for channel: OrigAGP for high_confluence\n",
      "Early termination at epoch 28 with best validation metric -0.008496610017923208\n",
      "Beginning training wGAN-gp for channel: OrigMito for high_confluence\n",
      "Early termination at epoch 37 with best validation metric -0.3187789022922516\n",
      "Beginning training wGAN-gp for channel: OrigRNA for high_confluence\n",
      "Early termination at epoch 32 with best validation metric -0.0027225567744328426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/26 15:20:42 INFO mlflow.tracking.fluent: Experiment with name 'wGAN_gp_prototype_train_low_confluence' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training wGAN-gp for channel: OrigDNA for low_confluence\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DEVICE = 'cuda'\n",
    "\n",
    "import gc\n",
    "def free_gpu_memory():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "## Train data split loaddata\n",
    "loaddata_df = pd.read_csv(LOADDATA_FILE_PATH)\n",
    "\n",
    "## Iterate over confluence group\n",
    "for confluence_group_name, conditions in DATA_GROUPING.items():\n",
    "\n",
    "    ## Subset Loaddata to confluence level\n",
    "    loaddata_condition_df = loaddata_df.copy()\n",
    "    for condition, values in conditions.items():\n",
    "        loaddata_condition_df = loaddata_condition_df[\n",
    "            loaddata_condition_df[condition].isin(values)\n",
    "        ]\n",
    "\n",
    "    ## Retrieve relevant sc feature information\n",
    "    sc_features = pd.DataFrame()\n",
    "    for plate in loaddata_condition_df['Metadata_Plate'].unique():\n",
    "        sc_features_parquet = SC_FEATURES_DIR / f'{plate}_sc_normalized.parquet'\n",
    "        if not sc_features_parquet.exists():\n",
    "            print(f'{sc_features_parquet} does not exist, skipping...')\n",
    "            continue \n",
    "        else:\n",
    "            sc_features = pd.concat([\n",
    "                sc_features, \n",
    "                pd.read_parquet(\n",
    "                    sc_features_parquet,\n",
    "                    columns=['Metadata_Plate', 'Metadata_Well', 'Metadata_Site', 'Metadata_Cells_Location_Center_X', 'Metadata_Cells_Location_Center_Y']\n",
    "                )\n",
    "            ])\n",
    "\n",
    "    ## Generate multi-channel patch dataset for confluence group\n",
    "    pds = PatchDataset(\n",
    "        _loaddata_csv=loaddata_condition_df,\n",
    "        _sc_feature=sc_features,\n",
    "        _input_channel_keys=INPUT_CHANNEL_NAMES,\n",
    "        _target_channel_keys=TARGET_CHANNEL_NAMES,\n",
    "        _input_transform=PixelDepthTransform(src_bit_depth=16, target_bit_depth=8, _always_apply=True),\n",
    "        _target_transform=MinMaxNormalize(_normalization_factor=(2 ** 16) - 1, _always_apply=True),\n",
    "        patch_size=PATCH_SIZE,\n",
    "        verbose=False,\n",
    "        patch_generation_method=\"random_cell\",\n",
    "        n_expected_patches_per_img=50,\n",
    "        patch_generation_random_seed=42\n",
    "    )\n",
    "\n",
    "    ## Make folder for per confluence plotting\n",
    "    CONF_PLOT_DIR =  PLOT_DIR / confluence_group_name\n",
    "    CONF_PLOT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "    ## Train a model for each target channel\n",
    "    for channel_name in TARGET_CHANNEL_NAMES:\n",
    "\n",
    "        ## Make folder for per channel plotting under confluence\n",
    "        CHANNEL_CONF_PLOT_DIR =  CONF_PLOT_DIR / channel_name\n",
    "        CHANNEL_CONF_PLOT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "        ## Cache single input/single target dataset to speed up training\n",
    "        pds.set_input_channel_keys(INPUT_CHANNEL_NAMES)\n",
    "        pds.set_target_channel_keys(channel_name)\n",
    "        cds = CachedDataset(\n",
    "            dataset=pds,\n",
    "            prefill_cache=True\n",
    "        )\n",
    "\n",
    "        ## Configure input/target channel for heldout dataset for plotting\n",
    "        pds_heldout.set_input_channel_keys(INPUT_CHANNEL_NAMES)\n",
    "        pds_heldout.set_target_channel_keys(channel_name)\n",
    "\n",
    "        ## Iterate over the hardcoded generator depths and train a model for each\n",
    "        for GEN_DEPTH in GEN_DEPTHS:\n",
    "\n",
    "            DEPTH_CHANNEL_CONF_PLOT_DIR = CHANNEL_CONF_PLOT_DIR / channel_name\n",
    "            DEPTH_CHANNEL_CONF_PLOT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "            print(f\"Beginning prototype training wGAN-gp for channel: {channel_name} for {confluence_group_name} with generator depth: {GEN_DEPTH}\")\n",
    "\n",
    "            generator = UNet(\n",
    "                n_channels=1,\n",
    "                n_classes=1,\n",
    "                depth=GEN_DEPTH,\n",
    "                bilinear=False\n",
    "            )\n",
    "\n",
    "            discriminator = GlobalDiscriminator(\n",
    "                n_in_channels = 2, # 1 input brightfield + 1 target channel\n",
    "                n_in_filters = DISC_N_FILTERS,\n",
    "                _conv_depth = DISC_DEPTH,\n",
    "                _pool_before_fc = True\n",
    "            )\n",
    "\n",
    "            generator_optimizer = optim.Adam(generator.parameters(), \n",
    "                                            lr=GEN_OPTIM_LR, \n",
    "                                            betas=(GEN_OPTIM_BETA0, GEN_OPTIM_BETA1),\n",
    "                                            weight_decay=GEN_OPTIM_WEIGHT_DECAY)\n",
    "            discriminator_optimizer = optim.Adam(discriminator.parameters(), \n",
    "                                                lr=DISC_OPTIM_LR, \n",
    "                                                betas=(DISC_OPTIM_BETA0, DISC_OPTIM_BETA1),\n",
    "                                                weight_decay=DISC_OPTIM_WEIGHT_DECAY)\n",
    "\n",
    "            gp_loss = GradientPenaltyLoss(\n",
    "                _metric_name='gp_loss',\n",
    "                discriminator=discriminator,\n",
    "                weight=GP_WEIGHT,\n",
    "            )\n",
    "\n",
    "            gen_loss = GeneratorLoss(\n",
    "                _metric_name='gen_loss'\n",
    "            )\n",
    "\n",
    "            disc_loss = WassersteinLoss(\n",
    "                _metric_name='disc_loss'\n",
    "            )\n",
    "\n",
    "            params = {\n",
    "                        # generator optimizer hyperparameters\n",
    "                        'gen_optim_lr': GEN_OPTIM_LR,\n",
    "                        'gen_optim_beta0': GEN_OPTIM_BETA0,\n",
    "                        'gen_optim_beta1': GEN_OPTIM_BETA1,\n",
    "                        'gen_optim_weight_decay': GEN_OPTIM_WEIGHT_DECAY,\n",
    "                        # generator hyperparameters\n",
    "                        'gen_update_freq': GEN_UPDATE_FREQ,\n",
    "                        'gen_depth': GEN_DEPTH,\n",
    "                        # discriminator optimizer hyperparameters\n",
    "                        'disc_n_filters': DISC_N_FILTERS,\n",
    "                        'disc_optim_beta0': DISC_OPTIM_BETA0,\n",
    "                        'disc_optim_beta1': DISC_OPTIM_BETA1,\n",
    "                        'disc_optim_weight_decay': DISC_OPTIM_WEIGHT_DECAY,\n",
    "                        # discriminator hyperparameters\n",
    "                        'disc_update_freq': DISC_UPDATE_FREQ,\n",
    "                        'disc_depth': DISC_DEPTH,\n",
    "                        # gradient penalty weight\n",
    "                        'gp_loss_weight': GP_WEIGHT,\n",
    "                        # dataset hyperparameters\n",
    "                        'patch_size': PATCH_SIZE,\n",
    "                        'channel_name': channel_name,\n",
    "                        'confluence_group': confluence_group_name,\n",
    "                        # data loading hyperparameter(s)\n",
    "                        'batch_size': BATCH_SIZE,\n",
    "                        # training hyperparameters\n",
    "                        \"patience\": PATIENCE,\n",
    "                        \"epochs\": EPOCHS,                        \n",
    "                    }\n",
    "\n",
    "            mlflow_logger_callback = MlflowLogger(\n",
    "                    name='mlflow_logger',\n",
    "                    mlflow_uri=MLFLOW_DIR / 'mlruns',\n",
    "                    mlflow_experiment_name=f'wGAN_gp_prototype_train_{confluence_group_name}',\n",
    "                    mlflow_start_run_args={'run_name': f'wGAN_gp_prototype_train_{confluence_group_name}_{channel_name}_{GEN_DEPTH}', 'nested': True},\n",
    "                    mlflow_log_params_args=params,\n",
    "                )\n",
    "\n",
    "            plot_callback = IntermediatePlot(\n",
    "                name='plotter',\n",
    "                path=DEPTH_CHANNEL_CONF_PLOT_DIR,\n",
    "                dataset=pds_heldout,\n",
    "                indices=visualization_patch_indices, # every model being trained will have the same visualization patch indices\n",
    "                plot_metrics=[SSIM(_metric_name='ssim'), PSNR(_metric_name='psnr')],\n",
    "                figsize=(20, 25),\n",
    "                every_n_epochs=5,\n",
    "                show_plot=False,\n",
    "            )\n",
    "\n",
    "            wgan_trainer = WGANTrainer(\n",
    "                dataset=cds,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCHS,\n",
    "                patience=PATIENCE, # setting this to prevent unwanted early termination here\n",
    "                device=TRAIN_DEVICE,\n",
    "                generator=generator,\n",
    "                discriminator=discriminator,\n",
    "                gen_optimizer=generator_optimizer,\n",
    "                disc_optimizer=discriminator_optimizer,\n",
    "                generator_loss_fn=gen_loss,\n",
    "                discriminator_loss_fn=disc_loss,\n",
    "                gradient_penalty_fn=gp_loss,\n",
    "                discriminator_update_freq=DISC_UPDATE_FREQ,\n",
    "                generator_update_freq=GEN_UPDATE_FREQ,\n",
    "                callbacks=[mlflow_logger_callback, plot_callback],\n",
    "                metrics=metric_fns,\n",
    "                early_termination_metric='L1Loss'\n",
    "            )\n",
    "\n",
    "            wgan_trainer.train()\n",
    "\n",
    "            del generator\n",
    "            del discriminator\n",
    "            del wgan_trainer\n",
    "\n",
    "            del mlflow_logger_callback\n",
    "            del plot_callback\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speckle_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
